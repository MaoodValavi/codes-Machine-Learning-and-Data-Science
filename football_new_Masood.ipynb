{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3LVrEHKgsiXT"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    HistGradientBoostingClassifier,\n",
    "    VotingClassifier,\n",
    "    StackingClassifier)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "import warnings\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qh1Gg3-KsiXU",
    "outputId": "562b933f-6251-4c98-98eb-95141d38e339"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading historical data: 100%|█████████████████████████████████████████████████| 550/550 [01:51<00:00,  4.95file/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Div        Date   HomeTeam    AwayTeam  FTHG  FTAG FTR  HTHG  HTAG HTR  ...  \\\n",
      "0  F1  2000-07-28   Paris SG  Strasbourg   3.0   1.0   H   1.0   1.0   D  ...   \n",
      "1  F1  2000-07-28  Marseille      Troyes   3.0   1.0   H   2.0   1.0   H  ...   \n",
      "2  F2  2000-07-28  Wasquehal       Nancy   0.0   1.0   A   0.0   1.0   A  ...   \n",
      "3  F1  2000-07-29       Lyon      Rennes   2.0   2.0   D   0.0   2.0   A  ...   \n",
      "4  F1  2000-07-29      Lille      Monaco   1.0   1.0   D   0.0   1.0   A  ...   \n",
      "\n",
      "   HC  AC  HF  AF  HST  AST  HY  AY  HR  AR  \n",
      "0 NaN NaN NaN NaN  NaN  NaN NaN NaN NaN NaN  \n",
      "1 NaN NaN NaN NaN  NaN  NaN NaN NaN NaN NaN  \n",
      "2 NaN NaN NaN NaN  NaN  NaN NaN NaN NaN NaN  \n",
      "3 NaN NaN NaN NaN  NaN  NaN NaN NaN NaN NaN  \n",
      "4 NaN NaN NaN NaN  NaN  NaN NaN NaN NaN NaN  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import logging\n",
    "from io import StringIO\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set logging configuration\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Constants\n",
    "DOWNLOADING_OPTION = 1  # 1 for web scraping, 0 for using saved data\n",
    "SEASONS = range(2000, 2025)\n",
    "TO_KEEP = [\n",
    "    'Div', 'Date', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR', 'HTHG', 'HTAG', 'HTR',\n",
    "    'HS', 'AS', 'HC', 'AC', 'HF', 'AF', 'HST', 'AST', 'HY', 'AY', 'HR', 'AR', 'B365H', 'B365D', 'B365A',\n",
    "    'B365>2.5', 'B365<2.5'\n",
    "]\n",
    "\n",
    "DICT_COUNTRIES = {\n",
    "    \"Spanish La Liga\": \"SP1\", \"Spanish Segunda Division\": \"SP2\", \"German Bundesliga\": \"D1\",\n",
    "    \"German Bundesliga 2\": \"D2\", \"Italian Serie A\": \"I1\", \"Italian Serie B\": \"I2\",\n",
    "    \"English Premier League\": \"E0\", \"English Championship\": \"E1\", \"English League 1\": \"E2\",\n",
    "    \"English League C\": \"EC\", \"English League 2\": \"E3\", \"French Ligue 1\": \"F1\",\n",
    "    \"French Ligue 2\": \"F2\", \"Dutch Eredivisie\": \"N1\", \"Belgian First Division A\": \"B1\",\n",
    "    \"Portuguese Primeira Liga\": \"P1\", \"Turkish Super League\": \"T1\", \"Greek Super League\": \"G1\",\n",
    "    \"Scottish Premier League\": \"SC0\", \"Scottish League1\": \"SC1\", \"Scottish League2\": \"SC2\",\n",
    "    \"Scottish League3\": \"SC3\"\n",
    "}\n",
    "\n",
    "DICT_OTHERS = {\n",
    "    \"Argentina\": \"ARG\", \"Austria\": \"AUT\", \"Brazil\": \"BRA\", \"China\": \"CHN\",\n",
    "    \"Denmark\": \"DNK\", \"Finland\": \"FIN\", \"Ireland\": \"IRL\", \"Japan\": \"JPN\",\n",
    "    \"Mexico\": \"MEX\", \"Norway\": \"NOR\", \"Poland\": \"POL\", \"Romania\": \"ROM\",\n",
    "    \"Russia\": \"RUS\", \"Sweden\": \"SWE\", \"Switzerland\": \"SWZ\", \"USA\": \"USA\"\n",
    "}\n",
    "\n",
    "COMMON_COLUMNS = [\"Div\", \"Date\", \"HomeTeam\", \"AwayTeam\", \"FTHG\", \"FTAG\", \"FTR\", 'B365H', 'B365A', 'B365D']\n",
    "\n",
    "# Function to download data for DICT_COUNTRIES leagues\n",
    "def download_data(league, year):\n",
    "    s_year = int(str(year)[-2:])\n",
    "    url = f\"https://www.football-data.co.uk/mmz4281/{s_year}{(s_year + 1):02d}/{DICT_COUNTRIES[league]}.csv\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Use flexible reading to handle errors\n",
    "        matches = pd.read_csv(StringIO(response.text), on_bad_lines='skip')\n",
    "\n",
    "        # Select only columns that exist in the downloaded data\n",
    "        existing_columns = [col for col in TO_KEEP if col in matches.columns]\n",
    "        return matches[existing_columns]\n",
    "\n",
    "    except pd.errors.ParserError as e:\n",
    "        logging.warning(f\"Parser error for {league} - {year}: {e}\")\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Failed to download data for {league} - {year}: {e}\")\n",
    "    return None\n",
    "\n",
    "# Load data for other leagues in DICT_OTHERS and rename columns as needed\n",
    "def load_other_leagues():\n",
    "    other_data = []\n",
    "    for country, code in DICT_OTHERS.items():\n",
    "        try:\n",
    "            matches = pd.read_csv(f\"https://www.football-data.co.uk/new/{code}.csv\", on_bad_lines='skip')\n",
    "            # Rename columns to match the standard format\n",
    "            matches = matches.rename(columns={\n",
    "                \"League\": \"Div\", \"Home\": \"HomeTeam\", \"Away\": \"AwayTeam\",\n",
    "                \"HG\": \"FTHG\", \"AG\": \"FTAG\", \"Res\": \"FTR\",\n",
    "                \"PSCH\": \"B365H\", \"PSCD\": \"B365D\", \"PSCA\": \"B365A\"\n",
    "            })\n",
    "            other_data.append(matches[COMMON_COLUMNS])\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Failed to load data for {country}: {e}\")\n",
    "    return pd.concat(other_data, ignore_index=True) if other_data else pd.DataFrame()\n",
    "\n",
    "# Download and process data in parallel for DICT_COUNTRIES leagues\n",
    "def download_all_data():\n",
    "    data_frames = []\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        futures = [executor.submit(download_data, league, year) for league in DICT_COUNTRIES for year in SEASONS]\n",
    "        with tqdm(total=len(futures), unit='file', desc='Downloading historical data') as pbar:\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                matches = future.result()\n",
    "                if matches is not None:\n",
    "                    data_frames.append(matches)\n",
    "                pbar.update(1)\n",
    "    return pd.concat(data_frames, ignore_index=True) if data_frames else pd.DataFrame()\n",
    "\n",
    "if DOWNLOADING_OPTION:\n",
    "    # Download main leagues' data\n",
    "    matches_matches = download_all_data()\n",
    "    matches_matches['Date'] = pd.to_datetime(matches_matches['Date'], dayfirst=True, errors='coerce')\n",
    "    matches_matches.sort_values('Date', inplace=True)\n",
    "\n",
    "    # Create a subsample if needed\n",
    "    SUBSAMPLE_SIZE = -1\n",
    "    subset_matches = matches_matches.sample(n=SUBSAMPLE_SIZE, random_state=42) if SUBSAMPLE_SIZE > 0 else matches_matches.copy()\n",
    "    subset_matches['Date'] = subset_matches['Date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Load and process \"other leagues\" data\n",
    "    other_leagues = load_other_leagues()\n",
    "    other_leagues['Date'] = pd.to_datetime(other_leagues['Date'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Combine all data into final DataFrame\n",
    "    final_matches = pd.concat([subset_matches, other_leagues], ignore_index=True).reset_index(drop=True)\n",
    "    print(final_matches.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "uttG3AKDsiXV",
    "outputId": "bf4a2e06-5d5e-4020-d194-437ef82906d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoders saved successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>B365H</th>\n",
       "      <th>B365D</th>\n",
       "      <th>B365A</th>\n",
       "      <th>B365&lt;2.5</th>\n",
       "      <th>...</th>\n",
       "      <th>Norm_Prob_D</th>\n",
       "      <th>Norm_Prob_A</th>\n",
       "      <th>HomeOdds_5</th>\n",
       "      <th>AwayOdds_5</th>\n",
       "      <th>HomeGoalsScored_5</th>\n",
       "      <th>AwayGoalsScored_5</th>\n",
       "      <th>HomeGoalsConceded_5</th>\n",
       "      <th>AwayGoalsConceded_5</th>\n",
       "      <th>Home_Win_Streak</th>\n",
       "      <th>Away_Win_Streak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>154</td>\n",
       "      <td>144</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>1.95</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241969</td>\n",
       "      <td>0.292705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>66</td>\n",
       "      <td>451</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>D</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.45</td>\n",
       "      <td>1.88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293267</td>\n",
       "      <td>0.389027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>511</td>\n",
       "      <td>460</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>2.15</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.275112</td>\n",
       "      <td>0.302623</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>503</td>\n",
       "      <td>15</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "      <td>1.62</td>\n",
       "      <td>3.80</td>\n",
       "      <td>4.75</td>\n",
       "      <td>1.98</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241215</td>\n",
       "      <td>0.192972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>339</td>\n",
       "      <td>335</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>D</td>\n",
       "      <td>6.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.44</td>\n",
       "      <td>2.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227626</td>\n",
       "      <td>0.632296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  HomeTeam  AwayTeam  FTHG  FTAG FTR  B365H  B365D  B365A  \\\n",
       "0 2023-01-01       154       144   4.0   0.0   H   1.95   3.75   3.10   \n",
       "1 2023-01-01        66       451   1.0   1.0   D   3.00   3.25   2.45   \n",
       "2 2023-01-01       511       460   2.0   0.0   H   2.15   3.30   3.00   \n",
       "3 2023-01-01       503        15   4.0   1.0   H   1.62   3.80   4.75   \n",
       "4 2023-01-01       339       335   2.0   2.0   D   6.50   4.00   1.44   \n",
       "\n",
       "   B365<2.5  ...  Norm_Prob_D Norm_Prob_A  HomeOdds_5  AwayOdds_5  \\\n",
       "0      2.10  ...     0.241969    0.292705         0.0         0.0   \n",
       "1      1.88  ...     0.293267    0.389027         0.0         0.0   \n",
       "2      1.80  ...     0.275112    0.302623         0.0         0.0   \n",
       "3      1.98  ...     0.241215    0.192972         0.0         0.0   \n",
       "4      2.30  ...     0.227626    0.632296         0.0         0.0   \n",
       "\n",
       "   HomeGoalsScored_5  AwayGoalsScored_5  HomeGoalsConceded_5  \\\n",
       "0                0.0                0.0                  0.0   \n",
       "1                0.0                0.0                  0.0   \n",
       "2                0.0                0.0                  0.0   \n",
       "3                0.0                0.0                  0.0   \n",
       "4                0.0                0.0                  0.0   \n",
       "\n",
       "   AwayGoalsConceded_5  Home_Win_Streak  Away_Win_Streak  \n",
       "0                  0.0              0.0              0.0  \n",
       "1                  0.0              0.0              0.0  \n",
       "2                  0.0              0.0              0.0  \n",
       "3                  0.0              0.0              0.0  \n",
       "4                  0.0              0.0              0.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def preprocess_football_data_live(df, year):\n",
    "    # Step 1: Remove rows with missing values in key columns\n",
    "    required_columns = ['B365H', 'B365D', 'B365A', 'B365<2.5', 'B365>2.5']\n",
    "    df_filtered = df.dropna(subset=required_columns).copy()\n",
    "\n",
    "    # Step 2: Select relevant columns\n",
    "    col = ['Date', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR', 'B365H', 'B365D', 'B365A', 'B365<2.5', 'B365>2.5']\n",
    "    df_filtered = df_filtered[col]\n",
    "\n",
    "    # Step 3: Encode categorical columns\n",
    "    team_encoder = LabelEncoder()\n",
    "    outcome_encoder = LabelEncoder()\n",
    "    df_filtered['HomeTeam'] = team_encoder.fit_transform(df_filtered['HomeTeam'])\n",
    "    df_filtered['AwayTeam'] = team_encoder.transform(df_filtered['AwayTeam'])\n",
    "\n",
    "    # Step 4: Feature engineering\n",
    "    df_filtered['Implied_Prob_H'] = 1 / df_filtered['B365H'].replace({0: None})\n",
    "    df_filtered['Implied_Prob_D'] = 1 / df_filtered['B365D'].replace({0: None})\n",
    "    df_filtered['Implied_Prob_A'] = 1 / df_filtered['B365A'].replace({0: None})\n",
    "\n",
    "    df_filtered['Odds_Ratio_HA'] = df_filtered['B365H'] / df_filtered['B365A']\n",
    "    total_prob = df_filtered[['Implied_Prob_H', 'Implied_Prob_D', 'Implied_Prob_A']].sum(axis=1)\n",
    "    df_filtered['Norm_Prob_H'] = df_filtered['Implied_Prob_H'] / total_prob\n",
    "    df_filtered['Norm_Prob_D'] = df_filtered['Implied_Prob_D'] / total_prob\n",
    "    df_filtered['Norm_Prob_A'] = df_filtered['Implied_Prob_A'] / total_prob\n",
    "    df_filtered[['Norm_Prob_H', 'Norm_Prob_D', 'Norm_Prob_A']] = df_filtered[\n",
    "        ['Norm_Prob_H', 'Norm_Prob_D', 'Norm_Prob_A']\n",
    "    ].fillna(0)\n",
    "\n",
    "    # Step 5: Handle date and filter by year\n",
    "    df_filtered['Date'] = pd.to_datetime(df_filtered['Date'], errors='coerce')\n",
    "    df_filtered = df_filtered.dropna(subset=['Date'])\n",
    "    df_filtered = df_filtered[df_filtered['Date'].dt.year >= year].reset_index(drop=True)\n",
    "\n",
    "    # Rolling averages and streaks using `.shift(1)` to exclude the current match\n",
    "    df_filtered['HomeOdds_5'] = (\n",
    "        df_filtered.groupby('HomeTeam')['B365H']\n",
    "        .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())\n",
    "        .fillna(0)\n",
    "    )\n",
    "    df_filtered['AwayOdds_5'] = (\n",
    "        df_filtered.groupby('AwayTeam')['B365A']\n",
    "        .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    df_filtered['HomeGoalsScored_5'] = (\n",
    "        df_filtered.groupby('HomeTeam')['FTHG']\n",
    "        .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())\n",
    "        .fillna(0)\n",
    "    )\n",
    "    df_filtered['AwayGoalsScored_5'] = (\n",
    "        df_filtered.groupby('AwayTeam')['FTAG']\n",
    "        .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    df_filtered['HomeGoalsConceded_5'] = (\n",
    "        df_filtered.groupby('HomeTeam')['FTAG']\n",
    "        .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())\n",
    "        .fillna(0)\n",
    "    )\n",
    "    df_filtered['AwayGoalsConceded_5'] = (\n",
    "        df_filtered.groupby('AwayTeam')['FTHG']\n",
    "        .transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    df_filtered['Home_Win_Streak'] = (\n",
    "        df_filtered.groupby('HomeTeam')['FTR']\n",
    "        .transform(lambda x: (x.shift(1) == 'H').rolling(5).sum().fillna(0))\n",
    "    )\n",
    "    df_filtered['Away_Win_Streak'] = (\n",
    "        df_filtered.groupby('AwayTeam')['FTR']\n",
    "        .transform(lambda x: (x.shift(1) == 'A').rolling(5).sum().fillna(0))\n",
    "    )\n",
    "\n",
    "    # Step 6: Save encoders\n",
    "    os.makedirs('encoders', exist_ok=True)\n",
    "    joblib.dump(team_encoder, 'encoders/home_team_encoder.pkl')\n",
    "    joblib.dump(team_encoder, 'encoders/away_team_encoder.pkl')\n",
    "    joblib.dump(outcome_encoder, 'encoders/outcome_encoder.pkl')\n",
    "\n",
    "    print(\"Encoders saved successfully!\")\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "# Apply the preprocessing function to include rolling features and save encoders\n",
    "preprocessed_df = preprocess_football_data_live(final_matches, 2023)\n",
    "\n",
    "# Display the preprocessed DataFrame with new features\n",
    "preprocessed_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "FGLQ_X_AsiXW",
    "outputId": "5626784b-1e67-44c4-fad9-408737c60093"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>B365H</th>\n",
       "      <th>B365D</th>\n",
       "      <th>B365A</th>\n",
       "      <th>B365&lt;2.5</th>\n",
       "      <th>...</th>\n",
       "      <th>Norm_Prob_D</th>\n",
       "      <th>Norm_Prob_A</th>\n",
       "      <th>HomeOdds_5</th>\n",
       "      <th>AwayOdds_5</th>\n",
       "      <th>HomeGoalsScored_5</th>\n",
       "      <th>AwayGoalsScored_5</th>\n",
       "      <th>HomeGoalsConceded_5</th>\n",
       "      <th>AwayGoalsConceded_5</th>\n",
       "      <th>Home_Win_Streak</th>\n",
       "      <th>Away_Win_Streak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>154</td>\n",
       "      <td>144</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>1.95</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241969</td>\n",
       "      <td>0.292705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>66</td>\n",
       "      <td>451</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>D</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.45</td>\n",
       "      <td>1.88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293267</td>\n",
       "      <td>0.389027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>511</td>\n",
       "      <td>460</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>2.15</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.275112</td>\n",
       "      <td>0.302623</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>503</td>\n",
       "      <td>15</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "      <td>1.62</td>\n",
       "      <td>3.80</td>\n",
       "      <td>4.75</td>\n",
       "      <td>1.98</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241215</td>\n",
       "      <td>0.192972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>339</td>\n",
       "      <td>335</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>D</td>\n",
       "      <td>6.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.44</td>\n",
       "      <td>2.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227626</td>\n",
       "      <td>0.632296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  HomeTeam  AwayTeam  FTHG  FTAG FTR  B365H  B365D  B365A  \\\n",
       "0 2023-01-01       154       144   4.0   0.0   H   1.95   3.75   3.10   \n",
       "1 2023-01-01        66       451   1.0   1.0   D   3.00   3.25   2.45   \n",
       "2 2023-01-01       511       460   2.0   0.0   H   2.15   3.30   3.00   \n",
       "3 2023-01-01       503        15   4.0   1.0   H   1.62   3.80   4.75   \n",
       "4 2023-01-01       339       335   2.0   2.0   D   6.50   4.00   1.44   \n",
       "\n",
       "   B365<2.5  ...  Norm_Prob_D Norm_Prob_A  HomeOdds_5  AwayOdds_5  \\\n",
       "0      2.10  ...     0.241969    0.292705         0.0         0.0   \n",
       "1      1.88  ...     0.293267    0.389027         0.0         0.0   \n",
       "2      1.80  ...     0.275112    0.302623         0.0         0.0   \n",
       "3      1.98  ...     0.241215    0.192972         0.0         0.0   \n",
       "4      2.30  ...     0.227626    0.632296         0.0         0.0   \n",
       "\n",
       "   HomeGoalsScored_5  AwayGoalsScored_5  HomeGoalsConceded_5  \\\n",
       "0                0.0                0.0                  0.0   \n",
       "1                0.0                0.0                  0.0   \n",
       "2                0.0                0.0                  0.0   \n",
       "3                0.0                0.0                  0.0   \n",
       "4                0.0                0.0                  0.0   \n",
       "\n",
       "   AwayGoalsConceded_5  Home_Win_Streak  Away_Win_Streak  \n",
       "0                  0.0              0.0              0.0  \n",
       "1                  0.0              0.0              0.0  \n",
       "2                  0.0              0.0              0.0  \n",
       "3                  0.0              0.0              0.0  \n",
       "4                  0.0              0.0              0.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess the dataset and include form features\n",
    "finaldf = preprocessed_df.copy()#(final_matches, 2023)\n",
    "finaldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "r8YF8_TxsiXW",
    "outputId": "1dfed80f-a53d-46f4-96e7-cde77a397cc6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Div</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>B365H</th>\n",
       "      <th>B365D</th>\n",
       "      <th>B365A</th>\n",
       "      <th>B365&lt;2.5</th>\n",
       "      <th>B365&gt;2.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B1</td>\n",
       "      <td>31/01/2025</td>\n",
       "      <td>19:45</td>\n",
       "      <td>Oud-Heverlee Leuven</td>\n",
       "      <td>Mechelen</td>\n",
       "      <td>2.35</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.83</td>\n",
       "      <td>2.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B1</td>\n",
       "      <td>01/02/2025</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Charleroi</td>\n",
       "      <td>Dender</td>\n",
       "      <td>1.73</td>\n",
       "      <td>3.80</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1.85</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B1</td>\n",
       "      <td>01/02/2025</td>\n",
       "      <td>17:15</td>\n",
       "      <td>Cercle Brugge</td>\n",
       "      <td>Standard</td>\n",
       "      <td>1.83</td>\n",
       "      <td>3.40</td>\n",
       "      <td>4.33</td>\n",
       "      <td>1.70</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B1</td>\n",
       "      <td>01/02/2025</td>\n",
       "      <td>19:45</td>\n",
       "      <td>Genk</td>\n",
       "      <td>Beerschot VA</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5.50</td>\n",
       "      <td>10.00</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B1</td>\n",
       "      <td>02/02/2025</td>\n",
       "      <td>12:30</td>\n",
       "      <td>Antwerp</td>\n",
       "      <td>Club Brugge</td>\n",
       "      <td>4.75</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Div        Date   Time             HomeTeam      AwayTeam  B365H  B365D  \\\n",
       "0  B1  31/01/2025  19:45  Oud-Heverlee Leuven      Mechelen   2.35   3.25   \n",
       "1  B1  01/02/2025  15:00            Charleroi        Dender   1.73   3.80   \n",
       "2  B1  01/02/2025  17:15        Cercle Brugge      Standard   1.83   3.40   \n",
       "3  B1  01/02/2025  19:45                 Genk  Beerschot VA   1.25   5.50   \n",
       "4  B1  02/02/2025  12:30              Antwerp   Club Brugge   4.75   3.60   \n",
       "\n",
       "   B365A  B365<2.5  B365>2.5  \n",
       "0   3.00      1.83      2.03  \n",
       "1   4.50      1.85      2.00  \n",
       "2   4.33      1.70      2.10  \n",
       "3  10.00      2.70      1.44  \n",
       "4   1.73      2.10      1.70  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix = pd.read_csv('https://www.football-data.co.uk/fixtures.csv')[['Div', 'Date', 'Time', 'HomeTeam', 'AwayTeam',\n",
    "       'B365H', 'B365D', 'B365A', 'B365<2.5', 'B365>2.5']]\n",
    "fix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "hjA-4Hh7siXX"
   },
   "outputs": [],
   "source": [
    "df_filtered = finaldf.copy()\n",
    "\n",
    "# Step 7: Add calculated features\n",
    "df_filtered['is_draw'] = (df_filtered['FTHG'] == df_filtered['FTAG']).astype(int)\n",
    "df_filtered['hw_draw'] = (df_filtered['FTHG'] >= df_filtered['FTAG']).astype(int)\n",
    "df_filtered['aw_draw'] = (df_filtered['FTAG'] >= df_filtered['FTHG']).astype(int)\n",
    "df_filtered['ov_un_35'] = ((df_filtered['FTHG'] + df_filtered['FTAG']) >= 4).astype(int)\n",
    "df_filtered['ov_un_25'] = ((df_filtered['FTHG'] + df_filtered['FTAG']) >= 3).astype(int)\n",
    "df_filtered['ov_un_15'] = ((df_filtered['FTHG'] + df_filtered['FTAG']) >= 2).astype(int)\n",
    "df_filtered['is_ftr'] = df_filtered['FTR'].map({'H': 0, 'D': 1, 'A': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training for target: is_draw\n",
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
      "\n",
      "Best parameters for is_draw: {'bootstrap': False, 'max_depth': 45, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "Best Model Accuracy for is_draw: 0.84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.95      0.86      2445\n",
      "           1       0.93      0.74      0.82      2444\n",
      "\n",
      "    accuracy                           0.84      4889\n",
      "   macro avg       0.86      0.84      0.84      4889\n",
      "weighted avg       0.86      0.84      0.84      4889\n",
      "\n",
      "\n",
      "Training for target: hw_draw\n",
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
      "\n",
      "Best parameters for hw_draw: {'bootstrap': False, 'max_depth': 45, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "Best Model Accuracy for hw_draw: 0.82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.77      0.81      2322\n",
      "           1       0.79      0.86      0.82      2322\n",
      "\n",
      "    accuracy                           0.82      4644\n",
      "   macro avg       0.82      0.82      0.82      4644\n",
      "weighted avg       0.82      0.82      0.82      4644\n",
      "\n",
      "\n",
      "Training for target: aw_draw\n",
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
      "\n",
      "Best parameters for aw_draw: {'bootstrap': True, 'max_depth': 45, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "Best Model Accuracy for aw_draw: 0.68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.66      0.67      1867\n",
      "           1       0.67      0.71      0.69      1867\n",
      "\n",
      "    accuracy                           0.68      3734\n",
      "   macro avg       0.68      0.68      0.68      3734\n",
      "weighted avg       0.68      0.68      0.68      3734\n",
      "\n",
      "\n",
      "Training for target: ov_un_15\n",
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
      "\n",
      "Best parameters for ov_un_15: {'bootstrap': False, 'max_depth': 45, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "Best Model Accuracy for ov_un_15: 0.86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.78      0.85      2505\n",
      "           1       0.81      0.95      0.87      2505\n",
      "\n",
      "    accuracy                           0.86      5010\n",
      "   macro avg       0.87      0.86      0.86      5010\n",
      "weighted avg       0.87      0.86      0.86      5010\n",
      "\n",
      "\n",
      "Training for target: ov_un_25\n",
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
      "\n",
      "Best parameters for ov_un_25: {'bootstrap': True, 'max_depth': 45, 'min_samples_leaf': 3, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Best Model Accuracy for ov_un_25: 0.56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.58      0.57      1705\n",
      "           1       0.57      0.55      0.56      1704\n",
      "\n",
      "    accuracy                           0.56      3409\n",
      "   macro avg       0.56      0.56      0.56      3409\n",
      "weighted avg       0.56      0.56      0.56      3409\n",
      "\n",
      "\n",
      "Training for target: ov_un_35\n",
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
      "\n",
      "Best parameters for ov_un_35: {'bootstrap': False, 'max_depth': 45, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "Best Model Accuracy for ov_un_35: 0.81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.90      0.82      2342\n",
      "           1       0.88      0.71      0.79      2341\n",
      "\n",
      "    accuracy                           0.81      4683\n",
      "   macro avg       0.82      0.81      0.81      4683\n",
      "weighted avg       0.82      0.81      0.81      4683\n",
      "\n",
      "\n",
      "Training for target: is_ftr\n",
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
      "\n",
      "Best parameters for is_ftr: {'bootstrap': False, 'max_depth': 45, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "Best Model Accuracy for is_ftr: 0.61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.63      0.60      1449\n",
      "           1       0.64      0.57      0.60      1450\n",
      "           2       0.61      0.62      0.62      1450\n",
      "\n",
      "    accuracy                           0.61      4349\n",
      "   macro avg       0.61      0.61      0.61      4349\n",
      "weighted avg       0.61      0.61      0.61      4349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "\n",
    "# Function to preprocess the data before training\n",
    "def preprocess_and_split(finaldf):\n",
    "    os.makedirs('saved_models', exist_ok=True)\n",
    "\n",
    "    # Features and target preparation\n",
    "    X = finaldf.drop(columns=['Date', 'hw_draw', 'aw_draw', 'ov_un_15', 'ov_un_25', 'ov_un_35',\n",
    "                              'is_draw', 'FTHG', 'FTAG', 'FTR', 'is_ftr'])\n",
    "\n",
    "    # Convert feature names to strings and remove special characters\n",
    "    X.columns = X.columns.astype(str).str.replace(r'[^a-zA-Z0-9_]', '', regex=True)\n",
    "\n",
    "    # Fill missing values with column means\n",
    "    X = X.fillna(X.mean()) \n",
    "\n",
    "    y_targets = finaldf[['is_draw', 'hw_draw', 'aw_draw', 'ov_un_15', 'ov_un_25', 'ov_un_35', 'is_ftr']]  \n",
    "\n",
    "    # Save feature names\n",
    "    feature_names = X.columns.tolist()\n",
    "    with open('saved_models/feature_names.pkl', 'wb') as f:\n",
    "        joblib.dump(feature_names, f)\n",
    "\n",
    "    # Apply scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Save the scaler\n",
    "    joblib.dump(scaler, 'saved_models/scaler.pkl')\n",
    "\n",
    "    return X_scaled, y_targets\n",
    "\n",
    "# Preprocess data\n",
    "X_scaled, y_targets = preprocess_and_split(df_filtered)\n",
    "\n",
    "# SMOTE for handling class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Hyperparameter tuning grid for Random Forest\n",
    "grid_params = {\n",
    "    'n_estimators': [100, 400],\n",
    "    'max_depth': [20, 45],\n",
    "    'min_samples_split': [2, 10],\n",
    "    'min_samples_leaf': [1, 3],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "for target in y_targets.columns:\n",
    "    print(f\"\\nTraining for target: {target}\")\n",
    "    y = y_targets[target]\n",
    "\n",
    "    # Handle class imbalance with SMOTE\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled\n",
    "    )\n",
    "\n",
    "    # Perform GridSearch for hyperparameter tuning\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    grid_search = GridSearchCV(estimator=rf, param_grid=grid_params, cv=3, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best model after tuning\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Print best hyperparameters\n",
    "    print(f\"\\nBest parameters for {target}: {grid_search.best_params_}\")\n",
    "\n",
    "    # Save the best model\n",
    "    model_path = f'saved_models/{target}_rf_model.pkl'\n",
    "    joblib.dump(best_model, model_path)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Best Model Accuracy for {target}: {accuracy:.2f}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating Training Accuracy for Target: is_draw\n",
      "Training Accuracy for is_draw: 0.35\n",
      "\n",
      "Calculating Training Accuracy for Target: hw_draw\n",
      "Training Accuracy for hw_draw: 0.32\n",
      "\n",
      "Calculating Training Accuracy for Target: aw_draw\n",
      "Training Accuracy for aw_draw: 0.37\n",
      "\n",
      "Calculating Training Accuracy for Target: ov_un_15\n",
      "Training Accuracy for ov_un_15: 0.34\n",
      "\n",
      "Calculating Training Accuracy for Target: ov_un_25\n",
      "Training Accuracy for ov_un_25: 0.31\n",
      "\n",
      "Calculating Training Accuracy for Target: ov_un_35\n",
      "Training Accuracy for ov_un_35: 0.30\n",
      "\n",
      "Calculating Training Accuracy for Target: is_ftr\n",
      "Training Accuracy for is_ftr: 0.36\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the saved feature names and scaler\n",
    "with open('saved_models/feature_names.pkl', 'rb') as f:\n",
    "    feature_names = joblib.load(f)\n",
    "\n",
    "scaler = joblib.load('saved_models/scaler.pkl')\n",
    "\n",
    "# Re-scale the training data\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "# Compute training accuracy for each target\n",
    "for target in y_targets.columns:\n",
    "    print(f\"\\nCalculating Training Accuracy for Target: {target}\")\n",
    "\n",
    "    # Load trained model\n",
    "    model_path = f'saved_models/{target}_rf_model.pkl'\n",
    "    best_model = joblib.load(model_path)\n",
    "\n",
    "    # Predict on training data\n",
    "    y_train_pred = best_model.predict(X_train_scaled)\n",
    "\n",
    "    # Calculate training accuracy\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    print(f\"Training Accuracy for {target}: {train_accuracy:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training for target: is_draw\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "\n",
      "Best parameters for is_draw: {'bootstrap': True, 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 15, 'n_estimators': 400}\n",
      "Best Model Accuracy for is_draw on Test Data: 0.73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.98      0.84      2445\n",
      "           1       0.16      0.01      0.02       872\n",
      "\n",
      "    accuracy                           0.73      3317\n",
      "   macro avg       0.45      0.50      0.43      3317\n",
      "weighted avg       0.58      0.73      0.62      3317\n",
      "\n",
      "Training Accuracy for is_draw: 0.96\n",
      "\n",
      "Training for target: hw_draw\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "\n",
      "Best parameters for hw_draw: {'bootstrap': True, 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 400}\n",
      "Best Model Accuracy for hw_draw on Test Data: 0.70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.35      0.41       995\n",
      "           1       0.75      0.86      0.80      2322\n",
      "\n",
      "    accuracy                           0.70      3317\n",
      "   macro avg       0.63      0.60      0.61      3317\n",
      "weighted avg       0.68      0.70      0.68      3317\n",
      "\n",
      "Training Accuracy for hw_draw: 0.99\n",
      "\n",
      "Training for target: aw_draw\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "\n",
      "Best parameters for aw_draw: {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 400}\n",
      "Best Model Accuracy for aw_draw on Test Data: 0.64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.61      0.59      1450\n",
      "           1       0.68      0.66      0.67      1867\n",
      "\n",
      "    accuracy                           0.64      3317\n",
      "   macro avg       0.63      0.63      0.63      3317\n",
      "weighted avg       0.64      0.64      0.64      3317\n",
      "\n",
      "Training Accuracy for aw_draw: 0.74\n",
      "\n",
      "Training for target: ov_un_15\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "\n",
      "Best parameters for ov_un_15: {'bootstrap': True, 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 400}\n",
      "Best Model Accuracy for ov_un_15 on Test Data: 0.74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.03      0.06       812\n",
      "           1       0.76      0.97      0.85      2505\n",
      "\n",
      "    accuracy                           0.74      3317\n",
      "   macro avg       0.50      0.50      0.45      3317\n",
      "weighted avg       0.63      0.74      0.66      3317\n",
      "\n",
      "Training Accuracy for ov_un_15: 1.00\n",
      "\n",
      "Training for target: ov_un_25\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "\n",
      "Best parameters for ov_un_25: {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Best Model Accuracy for ov_un_25 on Test Data: 0.57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.60      0.57      1612\n",
      "           1       0.59      0.54      0.56      1705\n",
      "\n",
      "    accuracy                           0.57      3317\n",
      "   macro avg       0.57      0.57      0.57      3317\n",
      "weighted avg       0.57      0.57      0.57      3317\n",
      "\n",
      "Training Accuracy for ov_un_25: 0.74\n",
      "\n",
      "Training for target: ov_un_35\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "\n",
      "Best parameters for ov_un_35: {'bootstrap': True, 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 400}\n",
      "Best Model Accuracy for ov_un_35 on Test Data: 0.69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.92      0.81      2342\n",
      "           1       0.43      0.15      0.23       975\n",
      "\n",
      "    accuracy                           0.69      3317\n",
      "   macro avg       0.58      0.54      0.52      3317\n",
      "weighted avg       0.64      0.69      0.64      3317\n",
      "\n",
      "Training Accuracy for ov_un_35: 1.00\n",
      "\n",
      "Training for target: is_ftr\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "\n",
      "Best parameters for is_ftr: {'bootstrap': True, 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 400}\n",
      "Best Model Accuracy for is_ftr on Test Data: 0.48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.65      0.60      1450\n",
      "           1       0.30      0.18      0.23       872\n",
      "           2       0.45      0.49      0.47       995\n",
      "\n",
      "    accuracy                           0.48      3317\n",
      "   macro avg       0.44      0.44      0.43      3317\n",
      "weighted avg       0.46      0.48      0.46      3317\n",
      "\n",
      "Training Accuracy for is_ftr: 0.99\n",
      "\n",
      "Training Accuracy Summary:\n",
      "is_draw: 0.96\n",
      "hw_draw: 0.99\n",
      "aw_draw: 0.74\n",
      "ov_un_15: 1.00\n",
      "ov_un_25: 0.74\n",
      "ov_un_35: 1.00\n",
      "is_ftr: 0.99\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Function to preprocess the data before training\n",
    "def preprocess_and_split(finaldf):\n",
    "    os.makedirs('saved_models', exist_ok=True)\n",
    "\n",
    "    # Features and target preparation\n",
    "    X = finaldf.drop(columns=['Date', 'hw_draw', 'aw_draw', 'ov_un_15', 'ov_un_25', 'ov_un_35',\n",
    "                              'is_draw', 'FTHG', 'FTAG', 'FTR', 'is_ftr'])\n",
    "\n",
    "    # Convert feature names to strings and remove special characters\n",
    "    X.columns = X.columns.astype(str).str.replace(r'[^a-zA-Z0-9_]', '', regex=True)\n",
    "\n",
    "    # Fill missing values with column means\n",
    "    X = X.fillna(X.mean()) \n",
    "\n",
    "    y_targets = finaldf[['is_draw', 'hw_draw', 'aw_draw', 'ov_un_15', 'ov_un_25', 'ov_un_35', 'is_ftr']]  \n",
    "\n",
    "    # Save feature names\n",
    "    feature_names = X.columns.tolist()\n",
    "    with open('saved_models/feature_names.pkl', 'wb') as f:\n",
    "        joblib.dump(feature_names, f)\n",
    "\n",
    "    return X, y_targets\n",
    "\n",
    "# Preprocess data\n",
    "X, y_targets = preprocess_and_split(df_filtered)\n",
    "\n",
    "# SMOTE for handling class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Hyperparameter tuning grid for Random Forest\n",
    "grid_params = {\n",
    "    'n_estimators': [100, 400],\n",
    "    'max_depth': [10, 30],  # Reduced depth to prevent overfitting\n",
    "    'min_samples_split': [5, 15],  # Increased min samples split\n",
    "    'min_samples_leaf': [2, 5],  # Prevent overfitting\n",
    "    'bootstrap': [True]\n",
    "}\n",
    "\n",
    "# Dictionary to store training accuracy for each target\n",
    "train_accuracies = {}\n",
    "\n",
    "for target in y_targets.columns:\n",
    "    print(f\"\\nTraining for target: {target}\")\n",
    "    y = y_targets[target]\n",
    "\n",
    "    # Train-test split before SMOTE\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Apply SMOTE **only on the training set**\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Scaling should be done separately for train and test\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_resampled)  # Fit only on training set\n",
    "    X_test_scaled = scaler.transform(X_test)  # Transform test set separately\n",
    "\n",
    "    # Save the scaler\n",
    "    joblib.dump(scaler, 'saved_models/scaler.pkl')\n",
    "\n",
    "    # Perform GridSearch for hyperparameter tuning\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    grid_search = GridSearchCV(estimator=rf, param_grid=grid_params, cv=3, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train_scaled, y_train_resampled)  # Only use training set!\n",
    "\n",
    "    # Get the best model after tuning\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Print best hyperparameters\n",
    "    print(f\"\\nBest parameters for {target}: {grid_search.best_params_}\")\n",
    "\n",
    "    # Save the best model\n",
    "    model_path = f'saved_models/{target}_rf_model.pkl'\n",
    "    joblib.dump(best_model, model_path)\n",
    "\n",
    "    # Evaluate the model on test data\n",
    "    y_pred = best_model.predict(X_test_scaled)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Best Model Accuracy for {target} on Test Data: {test_accuracy:.2f}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # --- 🔹 Training Accuracy Calculation ---\n",
    "    y_train_pred = best_model.predict(X_train_scaled)  # Predict on resampled & scaled training data\n",
    "    train_accuracy = accuracy_score(y_train_resampled, y_train_pred)  # Compare with resampled labels\n",
    "    print(f\"Training Accuracy for {target}: {train_accuracy:.2f}\")\n",
    "\n",
    "    # Store the training accuracy\n",
    "    train_accuracies[target] = train_accuracy\n",
    "\n",
    "# Print all training accuracies\n",
    "print(\"\\nTraining Accuracy Summary:\")\n",
    "for target, acc in train_accuracies.items():\n",
    "    print(f\"{target}: {acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "zMYeg3dUsiXY",
    "outputId": "cdd6f545-579a-465c-e1da-4728616ad1b5",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Div</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>B365H</th>\n",
       "      <th>B365D</th>\n",
       "      <th>B365A</th>\n",
       "      <th>B365&lt;2.5</th>\n",
       "      <th>B365&gt;2.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B1</td>\n",
       "      <td>31/01/2025</td>\n",
       "      <td>19:45</td>\n",
       "      <td>Oud-Heverlee Leuven</td>\n",
       "      <td>Mechelen</td>\n",
       "      <td>2.35</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.83</td>\n",
       "      <td>2.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B1</td>\n",
       "      <td>01/02/2025</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Charleroi</td>\n",
       "      <td>Dender</td>\n",
       "      <td>1.73</td>\n",
       "      <td>3.80</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1.85</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B1</td>\n",
       "      <td>01/02/2025</td>\n",
       "      <td>17:15</td>\n",
       "      <td>Cercle Brugge</td>\n",
       "      <td>Standard</td>\n",
       "      <td>1.83</td>\n",
       "      <td>3.40</td>\n",
       "      <td>4.33</td>\n",
       "      <td>1.70</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B1</td>\n",
       "      <td>01/02/2025</td>\n",
       "      <td>19:45</td>\n",
       "      <td>Genk</td>\n",
       "      <td>Beerschot VA</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5.50</td>\n",
       "      <td>10.00</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B1</td>\n",
       "      <td>02/02/2025</td>\n",
       "      <td>12:30</td>\n",
       "      <td>Antwerp</td>\n",
       "      <td>Club Brugge</td>\n",
       "      <td>4.75</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Div        Date   Time             HomeTeam      AwayTeam  B365H  B365D  \\\n",
       "0  B1  31/01/2025  19:45  Oud-Heverlee Leuven      Mechelen   2.35   3.25   \n",
       "1  B1  01/02/2025  15:00            Charleroi        Dender   1.73   3.80   \n",
       "2  B1  01/02/2025  17:15        Cercle Brugge      Standard   1.83   3.40   \n",
       "3  B1  01/02/2025  19:45                 Genk  Beerschot VA   1.25   5.50   \n",
       "4  B1  02/02/2025  12:30              Antwerp   Club Brugge   4.75   3.60   \n",
       "\n",
       "   B365A  B365<2.5  B365>2.5  \n",
       "0   3.00      1.83      2.03  \n",
       "1   4.50      1.85      2.00  \n",
       "2   4.33      1.70      2.10  \n",
       "3  10.00      2.70      1.44  \n",
       "4   1.73      2.10      1.70  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix = pd.read_csv('https://www.football-data.co.uk/fixtures.csv')[['Div', 'Date', 'Time', 'HomeTeam', 'AwayTeam',\n",
    "       'B365H', 'B365D', 'B365A', 'B365<2.5', 'B365>2.5']]\n",
    "fix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "VqMR2hEvsiXY",
    "outputId": "d5f0b8df-0e54-4b66-83c9-cc1ebafbe84e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Div        Date   Time             HomeTeam      AwayTeam  B365H  B365D  \\\n",
      "0    B1  31/01/2025  19:45  Oud-Heverlee Leuven      Mechelen   2.35   3.25   \n",
      "1    B1  01/02/2025  15:00            Charleroi        Dender   1.73   3.80   \n",
      "2    B1  01/02/2025  17:15        Cercle Brugge      Standard   1.83   3.40   \n",
      "3    B1  01/02/2025  19:45                 Genk  Beerschot VA   1.25   5.50   \n",
      "4    B1  02/02/2025  12:30              Antwerp   Club Brugge   4.75   3.60   \n",
      "..   ..         ...    ...                  ...           ...    ...    ...   \n",
      "187  T1  01/02/2025  16:00           Buyuksehyr    Samsunspor   2.15   3.30   \n",
      "188  T1  02/02/2025  10:30        Ad. Demirspor     Kasimpasa   3.90   3.80   \n",
      "189  T1  02/02/2025  13:00               Goztep    Alanyaspor   1.70   3.50   \n",
      "190  T1  02/02/2025  16:00           Fenerbahce      Rizespor   1.36   4.75   \n",
      "191  T1  03/02/2025  17:00            Gaziantep   Galatasaray   6.50   4.50   \n",
      "\n",
      "     B365A  B365<2.5  B365>2.5  Predicted_is_draw  Predicted_hw_draw  \\\n",
      "0     3.00      1.83      2.03                  0                  1   \n",
      "1     4.50      1.85      2.00                  0                  1   \n",
      "2     4.33      1.70      2.10                  1                  1   \n",
      "3    10.00      2.70      1.44                  0                  1   \n",
      "4     1.73      2.10      1.70                  0                  0   \n",
      "..     ...       ...       ...                ...                ...   \n",
      "187   3.25      1.75      2.05                  0                  1   \n",
      "188   1.75      2.35      1.57                  0                  0   \n",
      "189   4.33      1.95      1.90                  0                  1   \n",
      "190   8.50      2.40      1.53                  0                  1   \n",
      "191   1.40      2.88      1.40                  0                  1   \n",
      "\n",
      "     Predicted_aw_draw  Predicted_ov_un_15  Predicted_ov_un_25  \\\n",
      "0                    0                   1                   1   \n",
      "1                    0                   1                   1   \n",
      "2                    0                   1                   0   \n",
      "3                    0                   1                   1   \n",
      "4                    1                   1                   0   \n",
      "..                 ...                 ...                 ...   \n",
      "187                  1                   1                   0   \n",
      "188                  1                   1                   0   \n",
      "189                  0                   1                   1   \n",
      "190                  0                   1                   1   \n",
      "191                  1                   1                   0   \n",
      "\n",
      "     Predicted_ov_un_35  Predicted_is_ftr  \n",
      "0                     0                 0  \n",
      "1                     0                 0  \n",
      "2                     0                 1  \n",
      "3                     0                 0  \n",
      "4                     0                 2  \n",
      "..                  ...               ...  \n",
      "187                   0                 2  \n",
      "188                   0                 2  \n",
      "189                   0                 0  \n",
      "190                   0                 0  \n",
      "191                   0                 1  \n",
      "\n",
      "[192 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Function to preprocess upcoming matches\n",
    "def preprocess_upcoming_matches(fix, encoders):\n",
    "    df_upcoming = fix.copy()\n",
    "\n",
    "    # Ensure 'Date' column is in datetime format\n",
    "    df_upcoming['Date'] = pd.to_datetime(df_upcoming['Date'], format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "    # Function to safely encode team names\n",
    "    def safe_encode(column, encoder):\n",
    "        known_teams = set(encoder.classes_)  # Get all known team names\n",
    "\n",
    "        # Replace unseen teams with a default value (-1)\n",
    "        df_upcoming[column] = df_upcoming[column].apply(\n",
    "            lambda team: encoder.transform([team])[0] if team in known_teams else -1\n",
    "        )\n",
    "\n",
    "    # Encode categorical features using saved encoders, handling unknown teams\n",
    "    safe_encode('HomeTeam', encoders['home_team'])\n",
    "    safe_encode('AwayTeam', encoders['away_team'])\n",
    "\n",
    "    # Calculate Implied Probabilities\n",
    "    df_upcoming['Implied_Prob_H'] = 1 / df_upcoming['B365H'].replace({0: np.nan})\n",
    "    df_upcoming['Implied_Prob_D'] = 1 / df_upcoming['B365D'].replace({0: np.nan})\n",
    "    df_upcoming['Implied_Prob_A'] = 1 / df_upcoming['B365A'].replace({0: np.nan})\n",
    "\n",
    "    # Calculate Odds Ratio for Home and Away\n",
    "    df_upcoming['Odds_Ratio_HA'] = df_upcoming['B365H'] / df_upcoming['B365A']\n",
    "\n",
    "    # Normalize probabilities to sum to 1\n",
    "    total_prob = df_upcoming[['Implied_Prob_H', 'Implied_Prob_D', 'Implied_Prob_A']].sum(axis=1)\n",
    "    df_upcoming['Norm_Prob_H'] = df_upcoming['Implied_Prob_H'] / total_prob\n",
    "    df_upcoming['Norm_Prob_D'] = df_upcoming['Implied_Prob_D'] / total_prob\n",
    "    df_upcoming['Norm_Prob_A'] = df_upcoming['Implied_Prob_A'] / total_prob\n",
    "\n",
    "    # Replace NaN values resulting from division by zero\n",
    "    df_upcoming[['Norm_Prob_H', 'Norm_Prob_D', 'Norm_Prob_A']] = df_upcoming[\n",
    "        ['Norm_Prob_H', 'Norm_Prob_D', 'Norm_Prob_A']\n",
    "    ].fillna(0)\n",
    "\n",
    "    # Add placeholder columns for rolling averages and win streaks\n",
    "    for col in ['HomeOdds_5', 'AwayOdds_5', 'HomeGoalsScored_5', 'AwayGoalsScored_5',\n",
    "                'HomeGoalsConceded_5', 'AwayGoalsConceded_5', 'Home_Win_Streak', 'Away_Win_Streak']:\n",
    "        df_upcoming[col] = 0  # Placeholder if no history is available\n",
    "\n",
    "    return df_upcoming\n",
    "\n",
    "# Prediction function using trained Random Forest models\n",
    "def predict_upcoming_matches(fix, models, encoders, scaler):\n",
    "    # Preprocess the upcoming matches\n",
    "    df_upcoming = preprocess_upcoming_matches(fix, encoders)\n",
    "\n",
    "    # Load and align feature names\n",
    "    with open('saved_models/feature_names.pkl', 'rb') as f:\n",
    "        feature_names = joblib.load(f)\n",
    "    df_upcoming = df_upcoming.reindex(columns=feature_names, fill_value=0)\n",
    "\n",
    "    # Apply scaling\n",
    "    df_upcoming_scaled = scaler.transform(df_upcoming)\n",
    "\n",
    "    # Predict for each target using best-trained Random Forest models\n",
    "    predictions_results = {}\n",
    "    for target, model in models.items():\n",
    "        predictions_results[f'Predicted_{target}'] = model.predict(df_upcoming_scaled)\n",
    "\n",
    "    # Combine predictions with original data\n",
    "    predictions_df = pd.DataFrame(predictions_results)\n",
    "    final_results = pd.concat([fix.reset_index(drop=True), predictions_df], axis=1)\n",
    "\n",
    "    return final_results\n",
    "\n",
    "# Load encoders, scaler, and GridSearch-optimized models\n",
    "encoders = {\n",
    "    'home_team': joblib.load('encoders/home_team_encoder.pkl'),\n",
    "    'away_team': joblib.load('encoders/away_team_encoder.pkl'),\n",
    "}\n",
    "\n",
    "scaler = joblib.load('saved_models/scaler.pkl')\n",
    "\n",
    "# Load the trained Random Forest models\n",
    "models = {}\n",
    "targets = ['is_draw', 'hw_draw', 'aw_draw', 'ov_un_15', 'ov_un_25', 'ov_un_35', 'is_ftr']\n",
    "for target in targets:\n",
    "    models[target] = joblib.load(f'saved_models/{target}_rf_model.pkl')\n",
    "\n",
    "# Predict upcoming matches\n",
    "final_results = predict_upcoming_matches(fix, models, encoders, scaler)\n",
    "print(final_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "j4mCX6BGsiXY"
   },
   "outputs": [],
   "source": [
    "def predict_upcoming_matches_with_decoded_probs(fix, models, encoders, scaler):\n",
    "    # Define decoding mappings\n",
    "    decode_is_ftr = {0: 'Home Win', 1: 'Draw', 2: 'Away Win'}\n",
    "    decode_binary = {0: 'No', 1: 'Yes'}\n",
    "\n",
    "    # Preprocess the upcoming matches\n",
    "    df_upcoming = preprocess_upcoming_matches(fix, encoders)\n",
    "\n",
    "    # Load and align feature names\n",
    "    with open('saved_models/feature_names.pkl', 'rb') as f:\n",
    "        feature_names = joblib.load(f)\n",
    "    df_upcoming = df_upcoming.reindex(columns=feature_names, fill_value=0)\n",
    "\n",
    "    # Apply scaling\n",
    "    df_upcoming_scaled = scaler.transform(df_upcoming)\n",
    "\n",
    "    # Predict for each target and collect decoded predictions with probabilities\n",
    "    results = []\n",
    "    for idx, row in fix.iterrows():\n",
    "        match_result = {\n",
    "            \"Date\": row[\"Date\"],\n",
    "            \"Time\": row[\"Time\"],\n",
    "            \"HomeTeam\": row[\"HomeTeam\"],\n",
    "            \"AwayTeam\": row[\"AwayTeam\"],\n",
    "        }\n",
    "        for target, model in models.items():\n",
    "            # Prediction\n",
    "            prediction = model.predict([df_upcoming_scaled[idx]])[0]\n",
    "\n",
    "            # Decode Prediction\n",
    "            if target == 'is_ftr':\n",
    "                decoded_prediction = decode_is_ftr[prediction]\n",
    "            else:\n",
    "                decoded_prediction = decode_binary[prediction]\n",
    "            match_result[f\"Decoded_{target}\"] = decoded_prediction\n",
    "\n",
    "            # Respective Probability\n",
    "            if hasattr(model, \"predict_proba\"):\n",
    "                proba = model.predict_proba([df_upcoming_scaled[idx]])[0]\n",
    "                match_result[f\"Prob_{target}\"] = proba[prediction]\n",
    "        results.append(match_result)\n",
    "\n",
    "    # Convert results into a DataFrame\n",
    "    final_results = pd.DataFrame(results)\n",
    "    return final_results\n",
    "\n",
    "# Predict upcoming matches\n",
    "final_decoded_results = predict_upcoming_matches_with_decoded_probs(fix, models, encoders, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "7bsvoIfisiXY"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Convert Date column to datetime\n",
    "final_decoded_results[\"Date\"] = pd.to_datetime(final_decoded_results[\"Date\"], format=\"%d/%m/%Y\")\n",
    "\n",
    "# Refiltering with proper date format\n",
    "today = datetime.today().strftime(\"%d/%m/%Y\")  # Get today's date in the same format\n",
    "filtered_df = final_decoded_results[final_decoded_results[\"Date\"].dt.strftime(\"%d/%m/%Y\") == today]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "vgCy5ZoSsiXY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 15 Prob_is_draw Predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>Prob_is_draw</th>\n",
       "      <th>Predicted_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Date, Time, HomeTeam, AwayTeam, Prob_is_draw, Predicted_Class]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 15 Prob_hw_draw Predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>Prob_hw_draw</th>\n",
       "      <th>Predicted_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Date, Time, HomeTeam, AwayTeam, Prob_hw_draw, Predicted_Class]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 15 Prob_aw_draw Predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>Prob_aw_draw</th>\n",
       "      <th>Predicted_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Date, Time, HomeTeam, AwayTeam, Prob_aw_draw, Predicted_Class]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 15 Prob_ov_un_15 Predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>Prob_ov_un_15</th>\n",
       "      <th>Predicted_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Date, Time, HomeTeam, AwayTeam, Prob_ov_un_15, Predicted_Class]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 15 Prob_ov_un_25 Predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>Prob_ov_un_25</th>\n",
       "      <th>Predicted_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Date, Time, HomeTeam, AwayTeam, Prob_ov_un_25, Predicted_Class]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 15 Prob_ov_un_35 Predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>Prob_ov_un_35</th>\n",
       "      <th>Predicted_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Date, Time, HomeTeam, AwayTeam, Prob_ov_un_35, Predicted_Class]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 15 Prob_is_ftr Predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>Prob_is_ftr</th>\n",
       "      <th>Predicted_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Date, Time, HomeTeam, AwayTeam, Prob_is_ftr, Predicted_Class]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def display_top_n_predictions(df, probability_columns, n=3):\n",
    "    for col in probability_columns:\n",
    "        if \"Prob\" in col:\n",
    "            # Get the decoded column name and top N values\n",
    "            decoded_col = col.replace(\"Prob\", \"Decoded\")\n",
    "            top_n_df = df.nlargest(n, col)[[\"Date\", \"Time\", \"HomeTeam\", \"AwayTeam\", col]].copy()\n",
    "            top_n_df[\"Predicted_Class\"] = df.loc[top_n_df.index, decoded_col]\n",
    "\n",
    "            print(f\"\\nTop {n} {col} Predictions:\")\n",
    "            display(top_n_df)\n",
    "\n",
    "# List of probability columns\n",
    "probability_columns = [\"Prob_is_draw\", \"Prob_hw_draw\", \"Prob_aw_draw\", 'Prob_ov_un_15', \"Prob_ov_un_25\", 'Prob_ov_un_35', \"Prob_is_ftr\"]\n",
    "\n",
    "# Display top N for each category\n",
    "display_top_n_predictions(filtered_df, probability_columns, n=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "J6jmCKUTsiXY"
   },
   "outputs": [],
   "source": [
    "def best_predictions_per_match(final_results):\n",
    "    best_predictions = []\n",
    "\n",
    "    for _, row in final_results.iterrows():\n",
    "        match = {\n",
    "            \"Date\": row[\"Date\"],\n",
    "            \"Time\": row[\"Time\"],\n",
    "            \"HomeTeam\": row[\"HomeTeam\"],\n",
    "            \"AwayTeam\": row[\"AwayTeam\"],\n",
    "            \"FTR\": row[\"Decoded_is_ftr\"],\n",
    "            \"Prob_ftr\": row[\"Prob_is_ftr\"],\n",
    "        }\n",
    "\n",
    "        # Collect all predictions and probabilities\n",
    "        predictions = [\n",
    "            (\"is_draw\", row[\"Decoded_is_draw\"], row[\"Prob_is_draw\"]),\n",
    "            (\"is_ftr\", row[\"Decoded_is_ftr\"], row[\"Prob_is_ftr\"]),\n",
    "            (\"hw_draw\", row[\"Decoded_hw_draw\"], row[\"Prob_hw_draw\"]),\n",
    "            (\"aw_draw\", row[\"Decoded_aw_draw\"], row[\"Prob_aw_draw\"]),\n",
    "            (\"ov_un_25\", row[\"Decoded_ov_un_25\"], row[\"Prob_ov_un_25\"]),\n",
    "        ]\n",
    "\n",
    "        # Find the prediction with the highest probability\n",
    "        best_prediction = max(predictions, key=lambda x: x[2])  # Sort by probability\n",
    "        match[\"Best_Target\"] = best_prediction[0]\n",
    "        match[\"Best_Prediction\"] = best_prediction[1]\n",
    "        match[\"Best_Probability\"] = best_prediction[2]\n",
    "\n",
    "        best_predictions.append(match)\n",
    "\n",
    "    return pd.DataFrame(best_predictions)\n",
    "\n",
    "# Generate the DataFrame for best predictions\n",
    "best_predictions_df = best_predictions_per_match(final_decoded_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "fbktk3TAsiXZ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTR</th>\n",
       "      <th>Prob_ftr</th>\n",
       "      <th>Best_Target</th>\n",
       "      <th>Best_Prediction</th>\n",
       "      <th>Best_Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-31</td>\n",
       "      <td>19:45</td>\n",
       "      <td>Oud-Heverlee Leuven</td>\n",
       "      <td>Mechelen</td>\n",
       "      <td>Home Win</td>\n",
       "      <td>0.3850</td>\n",
       "      <td>hw_draw</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.735000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Charleroi</td>\n",
       "      <td>Dender</td>\n",
       "      <td>Home Win</td>\n",
       "      <td>0.5125</td>\n",
       "      <td>hw_draw</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.757500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>17:15</td>\n",
       "      <td>Cercle Brugge</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Draw</td>\n",
       "      <td>0.4450</td>\n",
       "      <td>hw_draw</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>19:45</td>\n",
       "      <td>Genk</td>\n",
       "      <td>Beerschot VA</td>\n",
       "      <td>Home Win</td>\n",
       "      <td>0.6575</td>\n",
       "      <td>hw_draw</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.905000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-02-02</td>\n",
       "      <td>12:30</td>\n",
       "      <td>Antwerp</td>\n",
       "      <td>Club Brugge</td>\n",
       "      <td>Away Win</td>\n",
       "      <td>0.5075</td>\n",
       "      <td>aw_draw</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.693945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>16:00</td>\n",
       "      <td>Buyuksehyr</td>\n",
       "      <td>Samsunspor</td>\n",
       "      <td>Away Win</td>\n",
       "      <td>0.3950</td>\n",
       "      <td>hw_draw</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.605000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>2025-02-02</td>\n",
       "      <td>10:30</td>\n",
       "      <td>Ad. Demirspor</td>\n",
       "      <td>Kasimpasa</td>\n",
       "      <td>Away Win</td>\n",
       "      <td>0.6175</td>\n",
       "      <td>aw_draw</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.789167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>2025-02-02</td>\n",
       "      <td>13:00</td>\n",
       "      <td>Goztep</td>\n",
       "      <td>Alanyaspor</td>\n",
       "      <td>Home Win</td>\n",
       "      <td>0.4825</td>\n",
       "      <td>is_draw</td>\n",
       "      <td>No</td>\n",
       "      <td>0.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>2025-02-02</td>\n",
       "      <td>16:00</td>\n",
       "      <td>Fenerbahce</td>\n",
       "      <td>Rizespor</td>\n",
       "      <td>Home Win</td>\n",
       "      <td>0.7450</td>\n",
       "      <td>hw_draw</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.887500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>2025-02-03</td>\n",
       "      <td>17:00</td>\n",
       "      <td>Gaziantep</td>\n",
       "      <td>Galatasaray</td>\n",
       "      <td>Draw</td>\n",
       "      <td>0.5450</td>\n",
       "      <td>aw_draw</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.820616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date   Time             HomeTeam      AwayTeam       FTR  Prob_ftr  \\\n",
       "0   2025-01-31  19:45  Oud-Heverlee Leuven      Mechelen  Home Win    0.3850   \n",
       "1   2025-02-01  15:00            Charleroi        Dender  Home Win    0.5125   \n",
       "2   2025-02-01  17:15        Cercle Brugge      Standard      Draw    0.4450   \n",
       "3   2025-02-01  19:45                 Genk  Beerschot VA  Home Win    0.6575   \n",
       "4   2025-02-02  12:30              Antwerp   Club Brugge  Away Win    0.5075   \n",
       "..         ...    ...                  ...           ...       ...       ...   \n",
       "187 2025-02-01  16:00           Buyuksehyr    Samsunspor  Away Win    0.3950   \n",
       "188 2025-02-02  10:30        Ad. Demirspor     Kasimpasa  Away Win    0.6175   \n",
       "189 2025-02-02  13:00               Goztep    Alanyaspor  Home Win    0.4825   \n",
       "190 2025-02-02  16:00           Fenerbahce      Rizespor  Home Win    0.7450   \n",
       "191 2025-02-03  17:00            Gaziantep   Galatasaray      Draw    0.5450   \n",
       "\n",
       "    Best_Target Best_Prediction  Best_Probability  \n",
       "0       hw_draw             Yes          0.735000  \n",
       "1       hw_draw             Yes          0.757500  \n",
       "2       hw_draw             Yes          0.825000  \n",
       "3       hw_draw             Yes          0.905000  \n",
       "4       aw_draw             Yes          0.693945  \n",
       "..          ...             ...               ...  \n",
       "187     hw_draw             Yes          0.605000  \n",
       "188     aw_draw             Yes          0.789167  \n",
       "189     is_draw              No          0.690000  \n",
       "190     hw_draw             Yes          0.887500  \n",
       "191     aw_draw             Yes          0.820616  \n",
       "\n",
       "[192 rows x 9 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the best predictions DataFrame\n",
    "best_predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "X0duCAhXsiXZ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTR</th>\n",
       "      <th>Prob_ftr</th>\n",
       "      <th>Best_Target</th>\n",
       "      <th>Best_Prediction</th>\n",
       "      <th>Best_Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Date, Time, HomeTeam, AwayTeam, FTR, Prob_ftr, Best_Target, Best_Prediction, Best_Probability]\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_predictions_df[best_predictions_df.Date=='2025-01-06'].nlargest(30,'Best_Probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "RngAsbUmsiXZ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>Decoded_ov_un_25</th>\n",
       "      <th>Prob_ov_un_25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Date, Time, HomeTeam, AwayTeam, Decoded_ov_un_25, Prob_ov_un_25]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_decoded_results[final_decoded_results.Date=='06/01/2025'][['Date', 'Time', 'HomeTeam', 'AwayTeam','Decoded_ov_un_25', 'Prob_ov_un_25']].nlargest(15,'Prob_ov_un_25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "NTN1xN6jsiXZ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>Decoded_is_draw</th>\n",
       "      <th>Prob_is_draw</th>\n",
       "      <th>Decoded_hw_draw</th>\n",
       "      <th>Prob_hw_draw</th>\n",
       "      <th>Decoded_aw_draw</th>\n",
       "      <th>Prob_aw_draw</th>\n",
       "      <th>Decoded_ov_un_15</th>\n",
       "      <th>Prob_ov_un_15</th>\n",
       "      <th>Decoded_ov_un_25</th>\n",
       "      <th>Prob_ov_un_25</th>\n",
       "      <th>Decoded_ov_un_35</th>\n",
       "      <th>Prob_ov_un_35</th>\n",
       "      <th>Decoded_is_ftr</th>\n",
       "      <th>Prob_is_ftr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Date, Time, HomeTeam, AwayTeam, Decoded_is_draw, Prob_is_draw, Decoded_hw_draw, Prob_hw_draw, Decoded_aw_draw, Prob_aw_draw, Decoded_ov_un_15, Prob_ov_un_15, Decoded_ov_un_25, Prob_ov_un_25, Decoded_ov_un_35, Prob_ov_un_35, Decoded_is_ftr, Prob_is_ftr]\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_decoded_results[final_decoded_results.Date=='06/01/2025'].nlargest(5,'Prob_ov_un_25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "MA0c-glhsiXZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
