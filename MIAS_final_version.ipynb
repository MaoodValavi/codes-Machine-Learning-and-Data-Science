{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnsSuSdEWzVp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import pandas as pd\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Settings\n",
        "image_size = 128\n",
        "batch_size = 25\n",
        "epochs = 100\n",
        "learning_rate = 0.001\n",
        "momentum = 0.9\n",
        "weight_decay = 0.0001\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load image paths and labels\n",
        "def load_data(data_dir, label_file):\n",
        "    df = pd.read_csv(label_file)\n",
        "    valid_exts = ['.pgm', '.tif', '.jpg', '.png']\n",
        "    image_paths, labels = [], []\n",
        "\n",
        "    for i, fname in enumerate(df['filename']):\n",
        "        found = False\n",
        "        for ext in valid_exts:\n",
        "            full_path = os.path.join(data_dir, fname + ext)\n",
        "            if os.path.isfile(full_path):\n",
        "                image_paths.append(full_path)\n",
        "                labels.append(df['label'][i])\n",
        "                found = True\n",
        "                break\n",
        "        if not found:\n",
        "            print(f\" Could not find image for: {fname} (tried {valid_exts})\")\n",
        "    return image_paths, labels\n",
        "\n",
        "# Custom dataset with augmentation\n",
        "class BreastCancerDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, augment=False):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.augment = augment\n",
        "\n",
        "        self.aug_transform = transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomRotation(degrees=10),\n",
        "            transforms.ColorJitter(contrast=0.1, brightness=0.1),\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if img is None:\n",
        "            raise FileNotFoundError(f\" Failed to load image at: {img_path}\")\n",
        "        img = cv2.equalizeHist(img)\n",
        "        img = cv2.resize(img, (image_size, image_size))\n",
        "\n",
        "        img = Image.fromarray(img)\n",
        "        if self.augment:\n",
        "            img = self.aug_transform(img)\n",
        "\n",
        "        img = np.expand_dims(np.array(img), axis=0).astype(np.float32) / 255.0\n",
        "        label = int(self.labels[idx])\n",
        "        return torch.tensor(img), torch.tensor(label)\n",
        "\n",
        "# CNN Model (Table 1)\n",
        "class CustomBreastCancerCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomBreastCancerCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=9, stride=1)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=7, stride=1)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=5, stride=1)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "        self.pool3 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, stride=1)\n",
        "        self.bn4 = nn.BatchNorm2d(128)\n",
        "        self.pool4 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.fc = nn.Linear(128 * 4 * 4, 4098)\n",
        "        self.output = nn.Linear(4098, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
        "        x = self.pool4(F.relu(self.bn4(self.conv4(x))))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc(x))\n",
        "        return self.output(x)\n",
        "\n",
        "# Training & Evaluation\n",
        "def train_and_evaluate(image_paths, labels):\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    fold_accuracies = []  # Store total combined accuracy per fold\n",
        "\n",
        "    for fold, (train_idx, test_idx) in enumerate(skf.split(image_paths, labels)):\n",
        "        print(f\"\\n--- Fold {fold+1} ---\")\n",
        "\n",
        "        # Reset counters for this fold\n",
        "        total_correct_train = 0\n",
        "        total_samples_train = 0\n",
        "        total_correct_test = 0\n",
        "        total_samples_test = 0\n",
        "\n",
        "        train_paths = [image_paths[i] for i in train_idx]\n",
        "        train_labels = [labels[i] for i in train_idx]\n",
        "        test_paths = [image_paths[i] for i in test_idx]\n",
        "        test_labels = [labels[i] for i in test_idx]\n",
        "\n",
        "        train_dataset = BreastCancerDataset(train_paths, train_labels, augment=True)\n",
        "        test_dataset = BreastCancerDataset(test_paths, test_labels, augment=False)\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "        model = CustomBreastCancerCNN().to(device)\n",
        "        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            model.train()\n",
        "            running_loss, correct_train, total_train = 0.0, 0, 0\n",
        "\n",
        "            for images, targets in train_loader:\n",
        "                images, targets = images.to(device), targets.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, targets)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                running_loss += loss.item()\n",
        "\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                correct_train += (preds == targets).sum().item()\n",
        "                total_train += targets.size(0)\n",
        "\n",
        "            # Evaluate on test\n",
        "            model.eval()\n",
        "            correct_test, total_test = 0, 0\n",
        "            with torch.no_grad():\n",
        "                for images, targets in test_loader:\n",
        "                    images, targets = images.to(device), targets.to(device)\n",
        "                    outputs = model(images)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    correct_test += (preds == targets).sum().item()\n",
        "                    total_test += targets.size(0)\n",
        "\n",
        "            train_acc = 100 * correct_train / total_train\n",
        "            test_acc = 100 * correct_test / total_test\n",
        "            print(f\"Epoch {epoch+1}/{epochs} â†’ Loss: {running_loss/len(train_loader):.4f}, \"\n",
        "                  f\"Train Acc: {train_acc:.2f}%, Test Acc: {test_acc:.2f}%\")\n",
        "\n",
        "        # Final accuracy calculation for this fold\n",
        "        total_correct_train += correct_train\n",
        "        total_samples_train += total_train\n",
        "        total_correct_test += correct_test\n",
        "        total_samples_test += total_test\n",
        "\n",
        "        total_correct_all = total_correct_train + total_correct_test\n",
        "        total_samples_all = total_samples_train + total_samples_test\n",
        "        total_accuracy = 100 * total_correct_all / total_samples_all\n",
        "        fold_accuracies.append(total_accuracy)\n",
        "\n",
        "        print(f\"\\n Total Combined Accuracy (Train + Test) for Fold {fold+1}: {total_accuracy:.2f}%\")\n",
        "\n",
        "    # After all folds\n",
        "    avg_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
        "    print(f\"\\n Average Combined Accuracy over all 5 folds: {avg_accuracy:.2f}%\")\n",
        "\n",
        "# Run\n",
        "image_paths, labels = load_data(\n",
        "    data_dir='C:/Users/masud/Personallaptob12Jan2025/Freelancer/Parscoders/11_Breast Cancer/allmias',\n",
        "    label_file='C:/Users/masud/Personallaptob12Jan2025/Freelancer/Parscoders/11_Breast Cancer/allmias/labels.csv'\n",
        ")\n",
        "\n",
        "train_and_evaluate(image_paths, labels)\n"
      ]
    }
  ]
}